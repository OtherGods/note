下面三种模式各有优劣，不存在最佳的模式，根据具体的业务场景选择合适自己的缓存读写模式即可。

# 1、Cache Aside Pattern（旁路缓存模式）

旁路缓存模式是我们平时用的比较多的一个缓存读写模式，比较适合读请求比较多的场景。

旁路缓存模式中服务端需要同时维系数据库（后文简称db）和缓存（后文简称cache），并且是以为db的结果为准。

下面是这个缓存策略模式下的缓存读写步骤：

1. 写

   1. <font color = "red">***先更新db***</font>
   2. <font color = "red">***再直接删除cache***</font>

   一张简图：
   ![image-20221014103454950](D:\Tyora\AssociatedPicturesInTheArticles\常见的缓存更新策略有哪些？\image-20221014103454950.png)

2. 读

   1. <font color = "red">***从cache中读取数据，读取到就直接返回。***</font>
   2. <font color = "red">***cache中读取不到的话，就从db中读取数据返回。***</font>
   3. <font color = "red">***再把db中读取到的数据放到cache中。***</font>

   一张简图：
   ![image-20221014103705250](D:\Tyora\AssociatedPicturesInTheArticles\常见的缓存更新策略有哪些？\image-20221014103705250.png)

仅了解这些内容还是不够的，还需要搞懂其中的原理。

## 1.1、为什么删除cache，而不是更新cache？

主要原因有两点：

1. **对服务端资源造成浪费**：删除cache更加直接，这是因为cache中存放的一些数据需要服务端经过大量的计算才能得出，会消耗服务端的资源，是一笔不小的开销。如果频繁修改db，会导致频繁更新cache，而且cache中的数据可能都没有被访问到。
2. **产生数据不一致问题**：并发场景下，更新cache产生数据不一致问题的概率会更大（后文会解释）

## 1.2、在写数据的过程中，可以先删除cache，后再更新db嘛？

不能，因为这样可以能造成数据库（db）和缓存）（Cache）数据不一致的问题。

举例：请求1先写数据A，请求2随后读数据A的话，就可能会产生数据不一致性的问题。这个过程可以简单描述为：

1. 请求1把cache中的A数据删除
2. 请求2从db中读取数据
3. 请求1再把db中的A数据更新

这就会导致请求2读取到的是旧值；因为请求1将cache中的数据删除后，请求2会去数据库中读旧的数据，读到的旧的数据存放在缓存中，之后请求1再把db中的A数据更新后，***db中的数据A和cache中 的数据A是不一致的***。

## 1.3、在写数据的过程中，先更新db，后删除cache就没有问题了嘛？

理论上来说还是可能会出现数据不一致的问题，不过概率很小，因为缓存的写入速度是比数据库的写入速度快很多。<font color = "red">***【延迟双删可以防止出现这种问题】***</font>

举例：请求1先读数据A，请求2随后写数据A，并且数据A在请求1请求之前不在缓存中的话，也有可能产生数据不一致性的问题；这个过程可以简单描述为：（过程中第三步和第四步顺序如果调换就会导致数据库不一致）

1. 请求1从db读取数据A(因为缓存中没有数据A)***【并且已经成功读取到，请求1的下一步就是将读到的内容写入缓存中】***
2. 请求2更新db中的数据A
3. 请求1将数据A写入cache中；***因为缓存的写入速度是比数据库的写入速度快很多，所以会先执行第三步，将数据A写入到cache中，之后才会删除cache【但是如先执行第4步就会导致缓存不一致的问题】***
4. 请求2删除cache

如果第4步在第3步之前执行，那么就会导致cache中存放的其实是旧值，但是这种情况出现的很少，因为缓存的写入速度是比数据库的写入速度快很多的。

现在我们再来分析一下**Cache Aside Pattern（旁路缓存）的缺陷**

1. **缺陷1：首先请求数据一定不在cache的问题**
   解决办法：可以将热点数据提前放入cache中。
2. **缺陷2：写操作比较频繁的话导致cache中的数据会被频繁的删除，这样会影响缓存命中率。**
   解决办法：
   1. 数据库和缓存数据一致场景：更新db的时候同样更新cache，不过我们需要加一个锁/分布式来保证更新cache的时候不存在线程安全问题。
   2. 可以短暂的允许数据库和缓存数据不一致的场景更新db的时候同样的更新cache，但是给缓存加一个比较短的过期时间，这样的话就可以保证即使数据不一致的话影响也是比较小。

# 2、Read/Write Through Pattern（读写穿透）

Read/Write Through Pattern中服务端把cache视为主要数据存储，从中读取数据并将数据写入其中。cache服务负责将此数据读取和写入db，从而减轻了应用程序的职责。

这种缓存读写策略我们平时在开发过程中很少见。抛去性能方面的影响，大概率是因为我们经常使用的分布式缓存Resid并没有提供cache将数据写入db的功能。

**写（Write Through）：**

1. 先查cache，cache中不存在，直接更新db
2. cache中存在，则先更新cache，然后cache服务自己更新db**（同步更新cache和db）**

![image-20221015153601649](D:\Tyora\AssociatedPicturesInTheArticles\常见的缓存更新策略有哪些？\image-20221015153601649.png)



**读（Red Through）：**

1. 从cache中读取数据，读取到就直接返回
2. 读取不到的话，先从db加载，写入到cache后返回响应

简单画了一张图如下：

![image-20221015153805193](D:\Tyora\AssociatedPicturesInTheArticles\常见的缓存更新策略有哪些？\image-20221015153805193.png)



Read-Through Pattern实际只是在Cache-Aside Pattern之上进行了封装。在Cache-Aside Pattern下，发生请求的时候，如果cache中不存在对应的数据，是由客户端自己负责把数据写入cache，而Read Through Pattren则是cache服务自己来写入缓存的，这对客户端是透明的。

和Cache Aside Pattern一样，Read-Through Pattern也有首次请求数据一定不在cache的问题，对于热点数据可以提前放入缓存中。

# 3、Write Behind Pattern（异步缓存写入）

这种模式和读写穿透（Read/Write Behind Pattern）很相似，两者都是由cache服务来负责cache和db的读写。

但是两个有很大的不同：Read/Write Through是同步更新cache和db，而Write Behind则是只更新缓存，不直接更新db，而是改为异步批量的方式更新db。

很明显，这种方式对数据一致性带来了更大的挑战，比如cache数据可能还没有异步更新db的话，cache服务可能就挂掉了。

这种策略在我们平时开发过程中非常少见，但是不代表它的应用场景很少，比如消息队列中消息的异步写入磁盘、MySQL的Innodb Buffer Pool机制都用到了这种策略。

Write Behind Pattern下db的写性能非常高，非常适合一些数据经常变化又对数据一致性要求没那么高的场景，比如：浏览量、点赞量。