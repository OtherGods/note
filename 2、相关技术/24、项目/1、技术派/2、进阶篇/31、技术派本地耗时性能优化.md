
一直有计划给大家整几篇关于性能调优、问题定位的实战类文章，秀一下我仅有的三板斧，之前没有找到合适的主题，因此一直搁置；正好有位小伙伴提了一个非常有意思的现状，借此机会，我们也来看一下，当出现问题之后，我们的应对步骤是哪些？

# 1、基于问题的复盘模板

按照小说的三要素，我们一般做问题分析/故障复盘时，也会有相应的几个要素;

本节内容以一个轻量的复盘形式，给大家描述一下整个问题的情况，方便有做复盘诉求小伙伴进行参考

## 1.1、问题概要

技术派的本地耗时相比较于生产环境高很多

## 1.2、影响范围

无实际业务影响，主要影响的是用户体验

## 1.3、全流程回顾

![image.png](https://raw.githubusercontent.com/OtherGods/MaterialImage/main/img/202403031353035.png)

> 全流程回顾主要是记录这个问题从发现到解决的整个周期内，各关键事件的触发时间点、相应的处理人、处理动作；
>  
> 稍微现实一点，它的主要作用就是衡量故障的影响范围、事故等级、需要背锅的人/团队，以及相关责任人的能力评定

题外话：

当我们看到这个表格的时候，心里就得清楚，问题来了之后，有一点进展就要及时同步出来，表明我们现在正在努力的处理这个问题，现在这个问题的处理动作正在往前推进，这样即便你花了两天才解决问题，最终给人的感受，比你一天解决完问题然后再同步反馈人问题已经修复，要好得多

另外补充一点，要想作为一个合格的职场人，学会分锅是一项必不可少的技能（加粗，仔细揣摩）

## 1.4、问题原因

> 这一节，则是主要分析为什么会出现这个问题，分表层原因（诱发这个问题的原因），根本原因（最终因为xxx导致会出现这个问题）

## 1.5、问题总结

基于上面的问题原因分析，小结一下整个故障的情况，比如有哪些做的不好的，需要改进的；有哪些做的ok的，值得推广的...

## 1.6、改进计划

改进计划就是针对上面问题总结中，不好的地方，给出对应的改进方案，并落实到具体的执行动作，交付的时间

# 2、问题定位全过程

这一篇的重心将在这一节内容，我会将我的整个问题的分析定位及修复的过程，尽量完整的还原出来；因为这个问题确实比较简单，看下面内容的小伙伴，重点放在思考的过程上，不要拘泥于手段

## 2.1、问题本地复现

基本上所反馈的后端相关的问题，并不是一上来就开始分析（当然也不排除某些特殊情况），通常第一步就是尝试再本地进行复现，基本上只要本地能复现的问题，那就都不会是难搞的问题

我们来实际看一下，本地的首页访问耗时情况：
![1.png](https://raw.githubusercontent.com/OtherGods/MaterialImage/main/img/202403031431226.png)

通过实际对比，本地耗时确实比生产环境上要多一倍；但是上初中(或者是高中？)的小伙伴，应该知道物理中有个控制变量法的对比策略，本机与服务器差异太多了，两者的对比结果能说明的问题实际上较小

当然这也不妨碍我们认定这个问题的存在，接下来我们进入问题的分析篇

## 2.2、问题定位分析全流程

看过技术派系列教程的小伙伴应该知道，我们借助Servlet的Filter实现了请求相关信息打印的功能，其中也记录了请求的耗时情况，我们先看一下这个耗时是否和浏览器上的表现一直
![1.png](https://raw.githubusercontent.com/OtherGods/MaterialImage/main/img/202403031434508.png)

从这个日志输出来看，整个耗时确实挺高；接下来我们会先猜测下，是不是因为首页返回的数据太多了，导致耗时高，那么先看下后端的数据拼接要多久？

直接再首页的后端实现上，把日志加上
![1.png](https://raw.githubusercontent.com/OtherGods/MaterialImage/main/img/202403031508917.png)

再次执行看看耗时情况
![1.png](https://raw.githubusercontent.com/OtherGods/MaterialImage/main/img/202403031508056.png)

后端整体接口耗时50ms，结果到浏览器访问居然要1.3s，这个量级差得有点夸张了，既然后端的数据耗时不多，那么盲猜测一下，是不是thymleaf的渲染耗时较高，因为我们开发环境是关闭了缓存的，难道是这个原因？

那我们把缓存开启再试一下
![1.png](https://raw.githubusercontent.com/OtherGods/MaterialImage/main/img/202403031523107.png)

然后再访问看下有没有性能提升
![1.png](https://raw.githubusercontent.com/OtherGods/MaterialImage/main/img/202403031523353.png)

实际结果却和我们预期不太一致，耗时依然没有改善；接下来咋办？

业务逻辑的耗时50ms，占整个耗时的1/20，接下来我们的目标就是找出到底是哪些地方比较耗时

此时我们可以借助Spring/Hutool的StopWatch来实现耗时统计（注意它不支持多线程），直接再Filter的各关键链路处，加上关键采样日志
> com.github.paicoding.forum.web.hook.filter.ReqRecordFilter#doFilter 添加日志采样

![1.png](https://raw.githubusercontent.com/OtherGods/MaterialImage/main/img/202403031530225.png)

再filter层，分别记录参数构建、业务逻辑、请求日志输出等节点的耗时分布，然后再多访问几次，看下耗时到底再那里![1.png](https://raw.githubusercontent.com/OtherGods/MaterialImage/main/img/202403031613706.png)

从上面的耗时分布来看，问题的源头应该就在这个请求参数构造这块逻辑里了，接下来要干的事情就简单了，重点看一下它里面干了些啥，到底是谁再拖后腿
![1.png](https://raw.githubusercontent.com/OtherGods/MaterialImage/main/img/202403031614224.png)

同样的执行几次之后，看下请求参数的耗时分布
![1.png](https://raw.githubusercontent.com/OtherGods/MaterialImage/main/img/202403031628186.png)

从上面的输出，可以看出耗时主要花在了traceId的构建 + 请求参数封装上，那就看下对应的源码

> com.github.paicoding.forum.core.mdc.SelfTraceIdGenerator#generate

![1.png](https://raw.githubusercontent.com/OtherGods/MaterialImage/main/img/202403031629873.png)

上面的traceId生成逻辑中，很方便可以缩小范围
1. 首先第一个ip的变量就是一个无效信息，因为后续没有使用到，这应该是明显的编写失误了,直接删掉
2. 2\3\4步骤，比较轻量，通常只会是ms以下的耗时；可疑点就在于本地ip获取上，针对于此我们同样可以再次进行耗时分布打印；但是我们这里采用更简单一点的策略

既然是获取本地ip，应用启动之后，这个ip时不变的，完全可以将其缓存下来，我们先加一个缓存来试试水
> com.github.paicoding.forum.core.util.IpUtil#getLocalIp4Address 缓存下本地ip

![1.png](https://raw.githubusercontent.com/OtherGods/MaterialImage/main/img/202403031636509.png)

然后再来看下效果如何
![1.png](https://raw.githubusercontent.com/OtherGods/MaterialImage/main/img/202403031637304.png)

这个优化效果逆天了啊，整体耗时直接到了100ms以下，十倍的性能提升，有木有！！！

只是这里还有一个小疑问，为啥本地ip缓存了一下，连请求基本信息构建这里也快了很多呢?

> 因为再获取请求来源ip时，针对本地的ip访问时，回调了上面的getLocalIp4Address()方法

![1.png](https://raw.githubusercontent.com/OtherGods/MaterialImage/main/img/202403031642535.png)

到此，整个问题的根源已经找到，且对应的优化方案也给出了；当然还是有进一步的提升空间的，比如请求参数构建 + 日志输出，目前合计依然占的耗时35%+，我们可以采用登录用户信息加缓存、异步输入日志等方式来进一步做性能提升

## 2.3、问题原因分析

前面找到了问题根源，获取本地网卡中的ip耗时较高；那为什么服务器上没有这个问题呢？【没看懂】
- 获取本地ip地址耗时500ms左右，本地访问2次；而服务器上只访问1次（clientIp解析不会走到调用getLocalIp4Address的逻辑）
- win本机上的网络接口信息远多于服务器上的网络接口信息

![1.png](https://raw.githubusercontent.com/OtherGods/MaterialImage/main/img/202403031659071.png)

## 2.4、线上验证

然后我们再将整个优化方案部署到生产环境，看下生产上是否有性能提升
![1.png](https://raw.githubusercontent.com/OtherGods/MaterialImage/main/img/202403031701747.png)
从上面的实际表现来看，基本上没啥效果 why?
![1.png](https://raw.githubusercontent.com/OtherGods/MaterialImage/main/img/202403031723373.png)

直接从后端请求日志上看对应的耗时情况，基本上都是六七十毫秒左右，但是浏览器端获取完整网页确实500ms，问题在哪里呢？

- 网络传输

因为某些大家都知道的原因，技术派的服务器搬迁到了新加坡，所以网络的耗时会更明显一些；接下来我们和之前的国内阿里云上服务器做一个对比

> 通过本地绑host到阿里云服务器来访问


![1.png](https://raw.githubusercontent.com/OtherGods/MaterialImage/main/img/202403031725491.png)

后端耗时相比较于sg服务器而言要多一点，但是网络访问整体耗时却要少200ms，从这个对比，也可以很明显的感受出来，为什么我们要做本地化部署，性能优化中为什么cdn是一个非常有效的手段

**扩展知识点：查看http请求耗时**
上面的对比，只是侧面表明网络耗时较多，那我们有办法查看整个请求中，每个阶段的耗时么？

这里直接借助curl来实现
```shell
curl -o /dev/null -s -w "time_namelookup: %{time_namelookup}\ntime_connect: %{time_connect}\ntime_appconnect:%{time_appconnect}\ntime_redirect: %{time_redirect}\ntime_pretransfer: %{time_pretransfer}\ntime_starttransfer: %{time_starttransfer}\ntime_total: %{time_total}\n" "https://paicoding.com"
```

参数解析说明
- -o /dev/null 把返回值丢掉，不用输出
- -s 静默输出，不输出进度条
- -w 按指定格式打印信息，其中包含一些特定的参数：
	- time_namelookup：从开始到域名解析完成时的耗时
	- time_connect：从开始到 TCP 连接建立完成的耗时
	- time_appconnect：从开始到 TLS 连接建立完成的耗时
	- time_redirect：多次重定向（如果有）的耗时
	- time_pretransfer：从开始到准备发送请求消息前的耗时
	- time_starttransfer：从开始到服务器准备返回第一个字节时的耗时
	- time_total：整个 HTTP 请求操作耗时
![1.png](https://raw.githubusercontent.com/OtherGods/MaterialImage/main/img/202403032227759.png)

通过上述输出，我们可以计算出各个步骤的时间，例如：
- DNS 解析：51ms
- TCP 连接：time_connect(0.136295s) - time_namelookup(0.051450s) = 84ms
- 服务器处理：time_starttransfer(0.450183s) - time_pretransfer(0.256244s) = 194ms

## 2.5、小结

整篇文章的内容相对来说比较简单，当然问题也很简单，重点是这个问题定位、性能优化的思路

接下来给大家提炼一下，问题定位的常见讨论
1. 尝试本地复现
2. 对于性能方面的问题，借助一些工具来打印耗时分布（如最简单有效的基于StopWatch来手动埋点记录，也可以借助skywalking类似的全链路追踪工具，当然也可以自己实现java agent来打印耗时)
3. 多次重复执行第二步，缩小问题范围，锚定根源
4. 针对实际情况采择对应的优化策略

常见的接口性能提升手段：
1. 加缓存（内存缓存guava > 分布式缓存redis)
2. 串行改并行
3. 异步
4. 池化：
	1. 提前生成需要的数据（如数据库的自增id、请求标识等）,需要时从资源池中获取，出一个则自动生成一个
	2. 重复利用资源，减少资源创建开销，如线程池、连接池

最后，我个人是希望并推荐每个看到这篇文章的小伙伴，可以仔细的将【2. 问题定位分析全流程】 这一小节的内容看一看，重点是这个思考过程，如果是你遇到一个之前从没有遇到的问题，你会怎样去排查定位呢？

我是一灰灰，欢迎有想法的小伙伴再评论区/星球/微信群继续讨论，也可以给出你们平常排解问题的思路、策略，大家一起学习进步