实现支付单/订单的到期关闭有很多种方案，大的层面是分来两种，一种是基于延迟消息，一种是基于定时任务。
- 延迟消息
	- kafka自己基于时间轮实现
	- RocketMQ 延迟消息/定时消息
	- RabbitMQ 死信队列
	- Redis 的 key 过期监听
- 定时任务
	- XXL-JOB
	- 时间轮
	- Redis 的 ZSET
	- Redisson 的延迟队列
	- DelayQueue

我们的项目中用了 RocketMQ 作为消息队列，为啥不直接使用他的延迟消息实现订单的到期关闭呢？

其实这个方案主要是参考了阿里内部的超时关单的方案，阿里内部没有使用 MQ，而是自研了一个 TOC（timeout center），其实底层主要就是基于分布式的定时任务来实现的。

之所以不用 MQ，主要是因为以下几个原因：

1. **资源占用与成本**：如果系统中存在大量订单，为每一个订单都创建一个延迟消息可能会导致消息队列中积压大量的消息，这不仅增加了消息队列的资源消耗，也可能导致增加成本，尤其是在使用云服务提供商的消息队列服务时。
2. **可靠性问题（重要）**：虽然消息队列一般来说可靠性较高，但是也没办法做到100%不丢消息，所以在极端情况下，会有丢消息的风险。
3. **大量无效消息（重要）**：使用MQ实现订单到期关闭就要把订单放到MQ中，但是大部分订单会提前取消或者完成支付，这就会导致很多无效的消息。
4. **扩展性问题**：随着系统规模的扩大，依赖于消息队列的延迟消息来处理订单到期可能遇到扩展性问题。系统可能需要更复杂的消息队列管理策略和更高效的资源利用策略来应对不断增长的订单量。

其中比较关键的是就是用了 MQ 之后，会存在可靠性的问题，还有就是可能会有大量的无效消息需要处理，浪费资源。所以，我们采用更加简单的定时任务的方案。

但是同时，定时任务也有自己的缺点，比如：

**1、延迟问题：** 定时调度没办法控制订单在到时间之后立刻关单，可能会存在延迟。

**2、性能问题：** 定时任务扫表，如果表中数据量太大，可能会带来性能的问题，又可能进一步导致堆积。

那么我们为了解决这个问题，我们在首先采用了 xxl-job 的分片任务，利用集群的能力来加速扫表。同时采用了生产者+消费者模式让扫表和消费之间进行解耦，并且在消费的时候采用线程池（ForkJoinPool）进行并发消费，来提升效率。

并且，为了减少避免延迟带来的影响，我们也采用了主动关单的方案，也就是说用户如果主动操作这个订单的时候，我们也会判断是否需要关单，如果需要，则先进性关单操作。