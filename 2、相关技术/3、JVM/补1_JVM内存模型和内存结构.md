# 1、第一种

## 1.1 JVM内存结构（运行时数据区）

![image-20221123160458855](D:\Tyora\AssociatedPicturesInTheArticles\JVM内存模型和内存结构\image-20221123160458855.png)

## 1.2 JVM内存模型（JMM）

JVM的目的是：**<u>*定义一种统一的内存模型，屏蔽掉各种底层硬件以及操作系统之间的差异，使Java程序在不同的硬件以及操作系统上并发执行的时候能够得到相同的结果。*</u>**



JMM是在底层处理器内存模型的基础上，定义自己的多线程语义。它明确制定了一组排序规则（Happens-Before），来保证线程间的可见性。

![image-20221123161729181](D:\Tyora\AssociatedPicturesInTheArticles\JVM内存模型和内存结构\image-20221123161729181.png)

这个规则可以保证可见性，举例：线程1释放锁退出同步代码块，线程2加上锁进入同步代码块，那么线程2就可以看见线程1对共享对象修改的结果。

![image-20221123162033849](D:\Tyora\AssociatedPicturesInTheArticles\JVM内存模型和内存结构\image-20221123162033849.png)







# 2、第二种（我认为更合适）

## 1、JVM内存模型

![image-20230527174953163](D:\Tyora\AssociatedPicturesInTheArticles\朗新\image-20230527174953163.png)

1. 程序计数器：指向当前线程要执行的字节码指令的位置；此区域是Java虚拟机中唯一一个没有OOM的区域

2. 虚拟机栈：虚拟机栈由一个个栈帧组成，每个方法在执行时都会创建一个栈帧用于存放局部变量（基本数据类型和对象引用）、操作数栈、方法出口、动态链接等信息，么一个方法从调用开始到执行完成就对应着一个栈帧在虚拟机栈中从入栈到出战的过程；可以抛出栈溢出（栈深度大于允许的最大值）、内存溢出。
   栈设置：

   1. -Xss1024k：设置栈大小为1024k相当于-XX:ThreadStack1024k

3. 本地方法栈：Sun HotSpot把虚拟机栈和本地方法栈合二为一了

4. 堆：JVM管理的最大一块内存区域，不要求物理连续，大小可以固定也可以扩展，是垃圾回收的主要区域，存储大多数对象实例和数组；可以抛出内存溢出异常。
   堆设置：

   1. -Xms1024k：设置堆的最小值为1024k相当于-XX:InitialHeap1024k
      【可以使用-Xmn或-XX:New1024k设置年轻代的堆的初始大小】
   2. -Xmx1024k：设置堆的最大值为1024k相当于-XX:MaxHeap1024k
      【可以使用-XX:MaxNew1024k设置年轻代的最大值】

5. 方法区：不要求物理连续，大小可以固定也可以动态扩展，可以进行/不进行垃圾回收，存放结构化定义的一些描述信息，例如类信息、JIT编译后的代码（比如Spring使用IOC或AOP创建bean时或使用cglib反射的形式动态生成class信息等）、常量、接口、方法、字段、运行时常量池（字面量、符号引用）。
   方法区设置：

   1. -XX:MetaspaceSize=1024k
   2. -XX:MaxMetaspaceSize=1024k

   在hotspot虚拟机中用永久代来实现方法区（jdk8之前），jdk8之后（包含）用元数据空间实现。【永久代存放在堆中，其中存放的内容导致这个区域经常OOM，所以改用元数据空间，放在本地内存中，内存有多大元数据空间有多大】。

   

## 2、JMM（Java内存模型）

![image-20230527183639252](D:\Tyora\AssociatedPicturesInTheArticles\朗新\image-20230527183639252.png)

### 2.1、数据不一致问题描述（我整理的）

计算机在执行程序的时候，每条指令都是在CPU中执行的，而执行指令的过程中，势必会涉及到数据的读取和写入。由于程序运行过程中的临时数据是存放在主存（物理内存）当中的，这时就存在一个问题，由于CPU执行速度很快，而CPU从内存读取数据和CPU向内存写入数据的过程跟CPU执行指令的速度比起来要慢的多，因此如果任何时候对数据的操作都要通过和内存的交互来进行，会大大降低指令执行的速度。因此在CPU里面就有了高速缓存。

当程序在运行过程中，会将运算需要的数据从内存中复制一份到CPU的高速缓存当中，那么CPU进行计算时就可以直接从它的高速缓存读取数据和向其中写入数据，当运算结束之后，再将高速缓存中的数据刷新到内存当中【至于是刷新到主内存还是本地内存就要看有没有被volatile修饰】。

线程间的共享变量存在主内存中，而对于每一个线程，都有一个私有的工作内存。工作内存是个虚拟的概念，涵盖了缓存，写缓冲区，寄存器以及其他的硬件和编译器优化，总之就是指线程的本地内存。存在线程本地内存中的变量值对其他线程是不可见的。**<font size = 5 color = "red">这就会产生数据不一致问题。</font>**

> 如果线程A与线程B之间如要通信的话，必须要经历下面2个步骤，如图所示：
> 	1. 首先，线程A把本地内存A中更新过的共享变量刷新到主内存中去。
> 	2. 然后，线程B到主内存中去读取线程A之前已更新过的共享变量。
> 	![image-20230614204824959](D:\Tyora\AssociatedPicturesInTheArticles\JVM内存模型和内存结构\image-20230614204824959.png)



### 2.2、什么是JMM（Hollis）

#### 2.2.1、典型回答 

Java程序是需要运行在Java虚拟机上面的，Java内存模型（Java Memory Model ,JMM）就是一种符合内存模型规范的，屏蔽了各种硬件和操作系统的访问差异的，保证了Java程序在各种平台下对内存的访问都能保证效果一致的机制及规范。

提到Java内存模型，一般指的是JDK 5 开始使用的新的内存模型，主要由JSR-133: JavaTM Memory Model and Thread Specification 描述（http://www.cs.umd.edu/~pugh/java/memoryModel/jsr133.pdf）

Java内存模型规定了所有的变量都存储在主内存中，每条线程还有自己的工作内存，线程的工作内存中保存了该线程中使用到的变量的主内存副本拷贝，**<font  size = 4 color = "red">线程对变量的所有操作（也就是CPU执行指令时）都必须在工作内存中（也就还是CPU高级缓存中）进行，而不能直接读写主内存，<font color = "purple">这样就存在数据一致性问题【参照2.2.2、扩展知识】</font></font>**。不同的线程之间也无法直接访问对方工作内存中的变量，线程间变量的传递均需要自己的工作内存和主存之间进行数据同步进行。

**<u>*而JMM就作用于工作内存和主存之间数据同步过程。他规定了如何做数据同步以及什么时候做数据同步。*</u>**

**<font color = "blue" size = 4>JMM是一种规范，目的是解决由于多线程通过共享内存进行通信时，存在的本地内存数据不一致、编译器会对代码指令重排序、处理器会对代码乱序执行等带来的问题。</font>**



#### 2.2.2、 扩展知识 



##### 2.2.2.1、计算机硬件升级带来的问题 

###### 2.2.2.1.1、多级缓存和一致性问题 

我们应该都知道，计算机在执行程序的时候，每条指令都是在CPU中执行的，而执行的时候，又免不了要和数据打交道。而计算机上面的数据，是存放在主存当中的，也就是计算机的物理内存啦。

刚开始，还相安无事的，但是随着CPU技术的发展，CPU的执行速度越来越快。而由于内存的技术并没有太大的变化，所以从内存中读取和写入数据的过程和CPU的执行速度比起来差距就会越来越大,这就导致CPU每次操作内存都要耗费很多等待时间。

可是，不能因为内存的读写速度慢，就不发展CPU技术了吧，总不能让内存成为计算机处理的瓶颈吧。

所以，人们想出来了一个好的办法，就是在CPU和内存之间增加高速缓存。缓存的概念大家都知道，就是保存一份数据拷贝。他的特点是速度快，内存小，并且昂贵。

那么，程序的执行过程就变成了：

**当程序在运行过程中，会将运算需要的数据从主存复制一份到CPU的高速缓存当中，那么CPU进行计算时就可以直接从它的高速缓存读取数据和向其中写入数据，当运算结束之后，再将高速缓存中的数据刷新到主存当中。**

而随着CPU能力的不断提升，一层缓存就慢慢的无法满足要求了，就逐渐的衍生出多级缓存。

按照数据读取顺序和与CPU结合的紧密程度，CPU缓存可以分为一级缓存（L1），二级缓存（L2），部分高端CPU还具有三级缓存（L3），每一级缓存中所储存的全部数据都是下一级缓存的一部分。

这三种缓存的技术难度和制造成本是相对递减的，所以其容量也是相对递增的。

那么，在有了多级缓存之后，程序的执行就变成了：

**当CPU要读取一个数据时，首先从一级缓存中查找，如果没有找到再从二级缓存中查找，如果还是没有就从三级缓存或内存中查找。**

单核CPU只含有一套L1，L2，L3缓存；如果CPU含有多个核心，即多核CPU，则每个核心都含有一套L1（甚至和L2）缓存，而共享L3（或者和L2）缓存。

下图为一个单CPU双核的缓存结构。

![image-20230614225932595](D:\Tyora\AssociatedPicturesInTheArticles\JVM内存模型和内存结构\image-20230614225932595.png)



随着计算机能力不断提升，开始支持多线程。那么问题就来了。我们分别来分析下单线程、多线程在单核CPU、多核CPU中的影响。



<font size = 4>**单线程。**</font> cpu核心的缓存只被一个线程访问。缓存独占，不会出现访问冲突等问题。

<font size = 4>**单核CPU，多线程。**</font> 进程中的多个线程会同时访问进程中的共享数据，CPU将某块内存加载到缓存后，不同线程在访问相同的物理地址的时候，都会映射到相同的缓存位置，这样即使发生线程的切换，缓存仍然不会失效。但由于任何时刻只能有一个线程在执行，因此不会出现缓存访问冲突。

<font size = 4>**多核CPU，多线程。**</font> 每个核都至少有一个L1 缓存。多个线程访问进程中的某个共享内存，且这多个线程分别在不同的核心上执行，则每个核心都会在各自的caehe中保留一份共享内存的缓冲。由于多核是可以并行的，可能会出现多个线程同时写各自的缓存的情况，而各自的cache之间的数据就有可能不同。

在CPU和主存之间增加缓存，<font color = "red" size = 4>**在多线程场景下就可能存在缓存一致性问题**</font>，也就是说，在多核CPU中，每个核的自己的缓存中，关于同一个数据的缓存内容可能不一致。

![image-20230614230135202](D:\Tyora\AssociatedPicturesInTheArticles\JVM内存模型和内存结构\image-20230614230135202.png)



###### 2.2.2.1.2、CPU时间片与原子性问题 



很多人都知道，现在我们用到操作系统，无论是Windows、Linux还是MacOS等其实都是多用户多任务分时操作系统。使用这些操作系统的“用户”是可以“同时”干多件事的，这已经是日常习惯了，并没觉得有什么特别。

但是实际上，对于单CPU的计算机来说，在CPU中，同一时间是只能干一件事儿的。

为了看起来像是“同时干多件事”，分时操作系统是把CPU的时间划分成长短基本相同的时间区间,即”时间片”，通过操作系统的管理，把这些时间片依次轮流地分配给各个“用户”使用。

如果某个“用户”在时间片结束之前，整个任务还没有完成，“用户”就必须进入到就绪状态，放弃CPU，等待下一轮循环。此时CPU又分配给另一个“用户”去使用。

> CPU 就好像是一个电话亭，他可以开放给所有用户使用，但是他有规定，每个用户进入电话亭之后只能使用规定时长的时间。如果时间到了，用户还没打完电话，那就会被要求去重新排队。
>



不同的操作系统，在选择“用户”分配时间片的调度算法是不一样的，常用的有FCFS、轮转、SPN、SRT、HRRN、反馈等，由于不是本文重点，就不展开了。

> 这个电话亭可以允许哪个用户进入打电话是有不同的策略的，不同的电话亭规定不同，有的电话亭采用排队机制（FCFS）、有的优先分配给打电话时间最短的人（SPN）等
>



我们说原子性问题，其实指的是多线程场景中操作如果不能保证原子性，会导致处理结果和预期不一致。

前面我们提到过，线程是CPU调度的基本单位。CPU有时间片的概念，会根据不同的调度算法进行线程调度。所以在多线程场景下，就会**<font color = "red" size=4>发生原子性问题</font>**。因为线程在执行一个读改写操作时，在执行完读改之后，时间片耗完，就会被要求放弃CPU，并等待重新调度。这种情况下，读改写就不是一个原子操作。

> 就好像我们去电话亭打电话，一共有三个步骤，查找电话，拨号，交流。由于我们在电话亭中可以停留的时间有限，有可能刚刚找到电话号码，时间到了，就被赶出来了。
>



在单线程中，一个读改写就算不是原子操作也没关系，因为只要这个线程再次被调度，这个操作总是可以执行完的。但是在多线程场景中可能就有问题了。因为多个线程可能会对同一个共享资源进行操作。

比如经典的 i++ 操作，对于一个简单的i++操作，一共有三个步骤：load , add ,save 。共享变量就会被多个线程同时进行操作，这样读改写操作就不是原子的，操作完之后共享变量的值会和期望的不一致，举个例子：如果i=1,我们进行两次i++操作，我们期望的结果是3，但是有可能结果是2。

![image-20230614230415255](D:\Tyora\AssociatedPicturesInTheArticles\JVM内存模型和内存结构\image-20230614230415255.png)



**<font size=4>并发中的原子性和数据库中的原子性 </font>**

原子性的概念是指：一个操作是不可中断的，要全部执行完成，要不就都不执行。

数据库事务中，保证原子性通过事务的提交和回滚，但是在并发编程中，是不涉及到回滚的。所以，并发编程中的原子性，强调的是一个操作的不可分割性。

所以，在并发编程中，原子性的定义不应该和事务中的原子性完全一样。他应该定义为：一段代码，或者一个变量的操作，在没有执行完之前，不能被其他线程执行。



###### 2.2.2.1.3、指令重排与有序性问题 

而且，我们知道，除了引入了时间片以外，由于处理器优化和指令重排等，CPU还可能对输入代码进行乱序执行，比如load->add->save 有可能被优化成load->save->add 。这就是有序性问题。

> 我们打电话的时候，除了可能被中途赶出来以外，本来正常步骤是要查找电话、拨号、交流的。但是电话亭非要给我们优化成查找电话、交流、拨号。这肯定不是我们想要的啊。
>

还是刚刚的i++操作，在满足了原子性的情况下，如果没有满足有序性，那么得到的结果可能也不是我们想要的。

![image-20230614230813088](D:\Tyora\AssociatedPicturesInTheArticles\JVM内存模型和内存结构\image-20230614230813088.png)



##### 2.2.2.2、计算机内存模型 

多CPU多级缓存导致的一致性问题、CPU时间片机制导致的原子性问题、以及处理器优化和指令重排导致的有序性问题等，都是硬件的不断升级导致的。那么，有没有什么机制可以很好的解决上面的这些问题呢？

最简单直接的做法就是废除处理器和处理器的优化技术、废除CPU缓存，让CPU直接和主存交互。但是，这么做虽然可以保证多线程下的并发问题。但是，这就有点因噎废食了。

**<font color = "red" size = 5>所以，为了保证并发编程中可以满足原子性、可见性及有序性。有一个重要的概念，那就是——内存模型。</font>**

***为了保证共享内存的正确性（可见性、有序性、原子性），内存模型定义了共享内存系统中多线程程序读写操作行为的规范***。通过这些规则来规范对内存的读写操作，从而保证指令执行的正确性。它与处理器有关、与缓存有关、与并发有关、与编译器也有关。他解决了CPU多级缓存、处理器优化、指令重排等导致的内存访问问题，保证了并发场景下的一致性、原子性和有序性。

**<font color = "red">内存模型解决并发问题主要采用两种方式：限制处理器优化和使用内存屏障。</font>**



##### 2.2.2.3、 Java内存模型的实现原理 

了解Java多线程的朋友都知道，在Java中提供了一系列和并发处理相关的关键字，比如volatile、synchronized、final、concurrent包等。其实这些就是Java内存模型封装了底层的实现后提供给程序员使用的一些关键字。

在开发多线程的代码的时候，我们可以直接使用synchronized等关键字来控制并发，从来就不需要关心底层的编译器优化、缓存一致性等问题。所以，Java内存模型，除了定义了一套规范，还提供了一系列原语，封装了底层实现后，供开发者直接使用。



###### 2.2.2.3.1、 原子性 

在Java中，为了保证原子性，提供了两个高级的字节码指令monitorenter和monitorexit。可以通过这两个指令来保证原子性。



###### 2.2.2.3.2、可见性 

Java内存模型是通过在变量修改后将新值同步回主内存，在变量读取前从主内存刷新变量值的这种依赖主内存作为传递媒介的方式来实现的。

Java中的volatile关键字提供了一个功能，那就是被其修饰的变量在被修改后可以立即同步到主内存，被其修饰的变量在每次使用之前都从主内存刷新。因此，可以使用volatile来保证多线程操作时变量的可见性。

除了volatile，Java中的synchronized和final两个关键字也可以实现可见性。只不过实现方式不同。



###### 2.2.2.3.3、 有序性 

在Java中，可以使用synchronized和volatile来保证多线程之间操作的有序性。实现方式有所区别：

volatile关键字会禁止指令重排。synchronized关键字保证同一时刻只允许一条线程操作。