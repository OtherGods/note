#深度分页 

# 典型回答

深度分页问题是指在数据库查询中，当你尝试访问通过分页查询返回的结果集的后面部分（即深层页码）时遇到的性能问题。

假设你有一个包含数百万条记录的表，你想通过分页的方式来展示这些数据。当用户请求第10000页数据时，假设pageSize为10，那么最终就是LIMIT 99990,10 ，数据库必须先扫描过前99990条记录，才能返回第10000页的数据，这会导致显著的性能下降。
> 99991是起始ID = (页数 - 1) * 每页项目数 + 1 
> 对于第1页，起始ID将是1，结束ID将是10。对于第2页，起始ID将是11，结束ID将是20，以此类推。
> 对于第10000页：
> 起始ID = (10000 - 1) * 10 + 1 = 99991

深度分页的问题想要优化，有以下几个手段。

## 使用子查询和JOIN优化（排序字段ID唯一且自增）

假如我们这样一条SQL：
```sql
SELECT c1, c2, cn... FROM table WHERE name = "Hollis" LIMIT 1000000,10
```

我们可以基于子查询进行优化，如以下SQL：
```sql
SELECT c1, c2, cn...
FROM table
INNER JOIN (
    SELECT id
    FROM table
    WHERE name = "Hollis"
    ORDER BY id
    LIMIT 1000000, 10
) AS subquery ON table.id = subquery.id
```

1. <font color="red" size=5>使用一个子查询来获取限定条件下的一小部分主键id</font>，这部分 id 对应于我们分页的目标区域
2. <font color="red" size=5>使用这些 id 在主查询中获取完整的行数据。</font>

以上SQL，在name有索引的情况下，**子查询中查询id是不需要回表的**。而当我们查询出我们想要的10个ID之后，基于ID查询不仅快，而且要查的数据量也很少。

## 使用子查询和ID过滤优化（排序字段ID唯一且自增）

和上面的方法类似，我们还可以把SQL优化成：
```sql
-- 先根据where条件通过id比较确定范围，再使用order by对查询结果进行排序，再使用limit
SELECT c1, c2, cn...
FROM table
WHERE name = "Hollis"
  AND id >= (SELECT id FROM table WHERE name = "Hollis" ORDER BY id LIMIT 1000000, 1)
ORDER BY id
LIMIT 10
```

这个方法代替了join的方式，使用了一个子查询来获取从哪里开始分页的参考点，基于ID做范围查询。

和上面的方案同理，他也可以减少回表的次数。

## 记录上一个ID（排序字段ID唯一且自增）

还有一种方式，是上面这个方式的变种，就是如果能提前预估要查询的分页的条件的话，是可以很大程度提升性能的。比如记住上一页的最大ID，下一页查询的时候，就可以可以根据`id >　max_id_in_last_page` 进行查询。

## 使用搜索引擎

另外，如果是基于文本内容的搜索，可以使用 Elasticsearch 这样的全文搜索引擎来优化深度分页性能。但是需要注意的是，ES也会有深度分页的问题，只不过他的影响比MySQL要小一些。

# 存在的问题(GPT+思考补充)

场景：定时任务循环分批扫表关单，在循环执行过程中可能会存在订单被取消关单（可能支付成功，这里就理解为删掉了），或者有一批新的订单需要关单

<font color="red" size=5>如果我们想要使用循环分批查询订单表时，前面JOIN优化和ID过滤两种方案都有弊端，那就是<font color=blue>要求排序字段ID一定要是唯一且自增的</font>，如果id不是唯一且自增，在循环中分批查询时其他地方插入（删除）了数据，且新插入（删除）的数据的id在<font color=blue>已排序且处理过</font>的数据id中间，那么在遍历的时候会有两个问题：①某些数据会漏掉、 ②已经过滤且处理的数据会被重复处理。</font>

如果排序键不是自增且唯一，可以使用 `创建时间 + 排序键值`：
```sql
-- 子查询
WHERE (create_time, id) >= (
  SELECT create_time, id
  FROM table
  WHERE name = 'Hollis'
  ORDER BY create_time, id
  LIMIT 1000000, 1
)
```

如果排序的键是自增且唯一，在新增数据时没有问题，但是在删除数据时存在问题，会导致部分数据被漏掉（因为使用limit），例如表中数据为：11、22、33、44、55、66、77，分页查询时一页两条，第二次分批循环查到第二页，数据为：33、44，下次循环应该应该查询数据：55、66，但是在第三次分批循环开始之前33被删掉了，而我们给JOIN优化和ID过滤中子查询中的limit传的是(4,2)，所以第三次分批循环查到的是66、77，导致数据55被漏掉，所以我们在分批循环扫表时通常用 [记录上一个ID（id唯一且自增）](2、相关技术/4、数据库-MySQL/Hollis/68、MySQL的深度分页如何优化.md#记录上一个ID（id唯一且自增）) 这种方式，如下：
```sql
-- 当id只唯一，但不自增时，可以结合时间字段（最好是创建时间这类被赋了一次值后就不会修改的字段）
-- 假设上一页最后一条是 create_time = '2024-07-01 10:00:00', id = '1050'
SELECT c1, c2, ...
FROM table
WHERE name = 'Hollis'
  AND (create_time, id) > ('2024-07-01 10:00:00', '1050')
ORDER BY create_time, id
LIMIT 10;
```
